{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31a41fec-c7f0-4752-b57a-efb428327343",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d51c63-ed05-43d4-9e02-7d13763b5011",
   "metadata": {},
   "source": [
    "This notebook demonstrates the use of **graph loader** in `pyTigerGraph`. The job of a data loader is to pull data from the TigerGraph database. Currently, the following data loaders are provided:\n",
    "* EdgeLoader, which returns batches of edges.\n",
    "* VertexLoader, which returns batches of vertices.\n",
    "* GraphLoader, which returns randomly sampled (probably disconnected) subgraphs in pandas `dataframe`, `PyG` or `DGL` format.\n",
    "* NeighborLoader, which returns subgraphs using neighbor sampling in `dataframe`, `PyG` or `DGL` format.\n",
    "* EdgeNeighborLoader, which returns subgraphs using neighbor sampling from edges in `dataframe`, `PyG` or `DGL` format.\n",
    "\n",
    "Every data loader above can either get all the batches as a HTTP response (default) or stream every batch through Kafka. The former mechanism is good for testing with small graphs and it is fast, but it subjects to a data size limit of 2GB. For large graphs, the HTTP channel will likely fail due to size limit and network connectivity issues. Streaming via Kafka is offered for data robustness and scalability. Also, Kafka excels at multi-consumer use cases, and it is efficient for model search or hyperparameter tuning when there are multiiple consumers of the same data. \n",
    "\n",
    "The data loaders support both homogeneous and heterogenous graphs. By default, they load from all vertex and edge types and treat the graph as a homogeneous graph. But they also allow users to specify what vertex and edge types to load from and what attributes to load from each type. This way users will get heterogeneous graph outputs.\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9243a4-69ae-4a04-ab82-dc6d393e0cb7",
   "metadata": {},
   "source": [
    "### Connection to Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff08e15-5d93-4f30-8a9d-6b101b1604e4",
   "metadata": {},
   "source": [
    "The `TigerGraphConnection` class represents a connection to the TigerGraph database. Under the hood, it stores the necessary information to communicate with the database. It is able to perform quite a few database tasks. Please see its [documentation](https://docs.tigergraph.com/pytigergraph/current/intro/) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2c4b1e8-a0e2-4026-9bb1-218cdc7ca4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A folder with name Cora already exists in ./tmp. Skip downloading.\n",
      "---- Checking database ----\n",
      "A graph with name Cora already exists in the database. Skip ingestion.\n",
      "Graph name is set to Cora for this connection.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "bf783068f4374adc8798356fc6400f47",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'circle', 'animate': True, 'padding': 1}, cytoscape_style=[{'selectoâ€¦"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyTigerGraph import TigerGraphConnection\n",
    "import json\n",
    "\n",
    "# Read in DB configs\n",
    "with open('../../config.json', \"r\") as config_file:\n",
    "    config = json.load(config_file)\n",
    "    \n",
    "conn = TigerGraphConnection(\n",
    "    host=config[\"host\"],\n",
    "    username=config[\"username\"],\n",
    "    password=config[\"password\"]\n",
    ")\n",
    "\n",
    "from pyTigerGraph.datasets import Datasets\n",
    "\n",
    "dataset = Datasets(\"Cora\")\n",
    "\n",
    "conn.ingestDataset(dataset, getToken=config[\"getToken\"])\n",
    "\n",
    "from pyTigerGraph.visualization import drawSchema\n",
    "\n",
    "drawSchema(conn.getSchema(force=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad2cc34-545d-4220-8938-e3eda1797fda",
   "metadata": {},
   "source": [
    "### Graph Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b490831c-409e-4234-9c7c-775273ca698b",
   "metadata": {},
   "source": [
    "`GraphLoader` pulls (possibly disconnected) subgraphs from database. Different from NeighborLoader which produces connected subgraphs, this loader gets (random) batches of edges and vertices attached to those edges.\n",
    "\n",
    "**Note**: For the first time you initialize the loader on a graph in TigerGraph, the initialization might take a minute as it installs the corresponding query to the database and optimizes it. However, the query installation only needs to be done once, so it will take no time when you initialize the loader on the same TG graph again.\n",
    "        \n",
    "There are two ways to use the data loader. See [here](https://github.com/TigerGraph-DevLabs/mlworkbench-docs/blob/main/tutorials/basics/2_dataloaders.ipynb) for examples.\n",
    "* First, it can be used as an iterable, which means you can loop through it to get every batch of data. If you load all data at once (`num_batches=1`), there will be only one batch (of all the data) in the iterator.\n",
    "* Second, you can access the `data` property of the class directly. If there is only one batch of data to load, it will give you the batch directly instead of an iterator, which might make more sense in that case. If there are multiple batches of data to load, it will return the loader itself.\n",
    "\n",
    "Args:\n",
    "* v_in_feats (list or dict, optional):\n",
    "        Vertex attributes to be used as input features. \n",
    "        If it is a list, then the attributes\n",
    "        in the list from all vertex types will be selected. An error will be thrown if\n",
    "        certain attribute doesn't exist in all vertex types. If it is a dict, keys of the \n",
    "        dict are vertex types to be selected, and values are lists of attributes to be \n",
    "        selected for each vertex type.\n",
    "        Only numeric and boolean attributes are allowed. The type of an attribute\n",
    "        is automatically determined from the database schema. Defaults to None.\n",
    "* v_out_labels (list or dict, optional):\n",
    "        Vertex attributes to be used as labels for prediction. \n",
    "        If it is a list, then the attributes\n",
    "        in the list from all vertex types will be selected. An error will be thrown if\n",
    "        certain attribute doesn't exist in all vertex types. If it is a dict, keys of the \n",
    "        dict are vertex types to be selected, and values are lists of attributes to be \n",
    "        selected for each vertex type.\n",
    "        Only numeric and boolean attributes are allowed. Defaults to None.\n",
    "* v_extra_feats (list or dict, optional):\n",
    "        Other attributes to get such as indicators of train/test data.\n",
    "        If it is a list, then the attributes\n",
    "        in the list from all vertex types will be selected. An error will be thrown if\n",
    "        certain attribute doesn't exist in all vertex types. If it is a dict, keys of the \n",
    "        dict are vertex types to be selected, and values are lists of attributes to be \n",
    "        selected for each vertex type. \n",
    "        All types of attributes are allowed. Defaults to None.\n",
    "* e_in_feats (list or dict, optional):\n",
    "        Edge attributes to be used as input features. \n",
    "        If it is a list, then the attributes\n",
    "        in the list from all edge types will be selected. An error will be thrown if\n",
    "        certain attribute doesn't exist in all edge types. If it is a dict, keys of the \n",
    "        dict are edge types to be selected, and values are lists of attributes to be \n",
    "        selected for each edge type.\n",
    "        Only numeric and boolean attributes are allowed. The type of an attribute\n",
    "        is automatically determined from the database schema. Defaults to None.\n",
    "* e_out_labels (list or dict, optional):\n",
    "        Edge attributes to be used as labels for prediction. \n",
    "        If it is a list, then the attributes in the list from all edge types will be \n",
    "        selected. An error will be thrown if certain attribute doesn't exist in all \n",
    "        edge types. If it is a dict, keys of the dict are edge types to be selected, \n",
    "        and values are lists of attributes to be selected for each edge type.\n",
    "        Only numeric and boolean attributes are allowed. Defaults to None.\n",
    "* e_extra_feats (list or dict, optional):\n",
    "        Other edge attributes to get such as indicators of train/test data. \n",
    "        If it is a list, then the attributes in the list from all edge types will be \n",
    "        selected. An error will be thrown if certain attribute doesn't exist in all \n",
    "        edge types. If it is a dict, keys of the dict are edge types to be selected, \n",
    "        and values are lists of attributes to be selected for each edge type.\n",
    "        All types of attributes are allowed. Defaults to None.\n",
    "* batch_size (int, optional):\n",
    "        Number of edges in each batch.\n",
    "        Defaults to None.\n",
    "* num_batches (int, optional):\n",
    "        Number of batches to split the edges.\n",
    "        Defaults to 1.\n",
    "* shuffle (bool, optional):\n",
    "        Whether to shuffle the data before loading.\n",
    "        Defaults to False.\n",
    "* filter_by (str, optional):\n",
    "        A boolean attribute used to indicate which edges can be included.\n",
    "        Defaults to None.\n",
    "* output_format (str, optional):\n",
    "        Format of the output data of the loader.\n",
    "        Only \"PyG\", \"DGL\" and \"dataframe\" are supported. Defaults to \"dataframe\".\n",
    "* add_self_loop (bool, optional):\n",
    "        Whether to add self-loops to the graph. Defaults to False.\n",
    "* loader_id (str, optional):\n",
    "        An identifier of the loader which can be any string. It is\n",
    "        also used as the Kafka topic name. If `None`, a random string will be generated\n",
    "        for it. Defaults to None.\n",
    "* buffer_size (int, optional):\n",
    "        Number of data batches to prefetch and store in memory. Defaults to 4.\n",
    "* timeout (int, optional):\n",
    "        Timeout value for GSQL queries, in ms. Defaults to 300000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e469fcf-dd49-459f-8731-5a398d7a66a8",
   "metadata": {},
   "source": [
    "# Testcase1: using graphLoader with callback_fn to get batches of graphs.(for homogeneous graph)    \n",
    "## Results: run successfully, data loaded completely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be7bada1-6c98-42ec-a5c5-e72a593615f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Batch 0----\n",
      "Data(edge_index=[2, 1037], edge_feat=[1037], is_train=[1037], is_val=[1037], x=[1008, 1433], y=[1008], train_mask=[1008], val_mask=[1008], test_mask=[1008])\n",
      "----Batch 1----\n",
      "Data(edge_index=[2, 1114], edge_feat=[1114], is_train=[1114], is_val=[1114], x=[1280, 1433], y=[1280], train_mask=[1280], val_mask=[1280], test_mask=[1280])\n",
      "----Batch 2----\n",
      "Data(edge_index=[2, 1095], edge_feat=[1095], is_train=[1095], is_val=[1095], x=[1279, 1433], y=[1279], train_mask=[1279], val_mask=[1279], test_mask=[1279])\n",
      "----Batch 3----\n",
      "Data(edge_index=[2, 1111], edge_feat=[1111], is_train=[1111], is_val=[1111], x=[1307, 1433], y=[1307], train_mask=[1307], val_mask=[1307], test_mask=[1307])\n",
      "----Batch 4----\n",
      "Data(edge_index=[2, 1047], edge_feat=[1047], is_train=[1047], is_val=[1047], x=[1164, 1433], y=[1164], train_mask=[1164], val_mask=[1164], test_mask=[1164])\n",
      "----Batch 5----\n",
      "Data(edge_index=[2, 987], edge_feat=[987], is_train=[987], is_val=[987], x=[972, 1433], y=[972], train_mask=[972], val_mask=[972], test_mask=[972])\n",
      "----Batch 6----\n",
      "Data(edge_index=[2, 1044], edge_feat=[1044], is_train=[1044], is_val=[1044], x=[1249, 1433], y=[1249], train_mask=[1249], val_mask=[1249], test_mask=[1249])\n",
      "----Batch 7----\n",
      "Data(edge_index=[2, 1076], edge_feat=[1076], is_train=[1076], is_val=[1076], x=[1281, 1433], y=[1281], train_mask=[1281], val_mask=[1281], test_mask=[1281])\n",
      "----Batch 8----\n",
      "Data(edge_index=[2, 1000], edge_feat=[1000], is_train=[1000], is_val=[1000], x=[1218, 1433], y=[1218], train_mask=[1218], val_mask=[1218], test_mask=[1218])\n",
      "----Batch 9----\n",
      "Data(edge_index=[2, 1045], edge_feat=[1045], is_train=[1045], is_val=[1045], x=[1150, 1433], y=[1150], train_mask=[1150], val_mask=[1150], test_mask=[1150])\n"
     ]
    }
   ],
   "source": [
    "def process_batch(batch):\n",
    "    return batch\n",
    "graph_loader2 = conn.gds.graphLoader(\n",
    "    num_batches=10,\n",
    "    v_in_feats = [\"x\"],\n",
    "    v_out_labels = [\"y\"],\n",
    "    v_extra_feats = [\"train_mask\", \"val_mask\", \"test_mask\"],\n",
    "    e_in_feats=[\"time\"],\n",
    "    e_out_labels=[],\n",
    "    e_extra_feats=[\"is_train\", \"is_val\"],\n",
    "    output_format = \"PyG\",\n",
    "    callback_fn = process_batch\n",
    ")\n",
    "for i, batch in enumerate(graph_loader2):\n",
    "    print(\"----Batch {}----\".format(i))\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4917e4af-392d-4c90-bc20-5d40324a30c4",
   "metadata": {},
   "source": [
    "# Testcase2: using graphLoader with callback_fn to get batchs of graphs(for heterogeneous graph).  \n",
    "## case details:using graphLoader without callback_fn first, then using graphLoader with the same paprams but set a callback_fn to get part of data.\n",
    "## Results: run successfully, data loaded completely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e56def3",
   "metadata": {},
   "source": [
    "Since `Cora` is a homogeneous graph, we will connect to a different graph to demostrate the use case of heterogeneous graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05616b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('6g7cvva0rt33rf8s8mprt24dockhlidp', 1674821647, '2023-01-27 12:14:07')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.graphname=\"hetero\"\n",
    "\n",
    "# COMMENT OUT THE LINE BELOW if you are NOT using a graph that requires token authentication\n",
    "conn.getToken(conn.createSecret())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a76b9591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Batch 0----\n",
      "HeteroData(\n",
      "  \u001b[1mv0\u001b[0m={\n",
      "    x=[76, 231],\n",
      "    y=[76],\n",
      "    train_mask=[76],\n",
      "    val_mask=[76],\n",
      "    test_mask=[76]\n",
      "  },\n",
      "  \u001b[1mv1\u001b[0m={ x=[110, 171] },\n",
      "  \u001b[1m(v0, v0v0, v0)\u001b[0m={\n",
      "    edge_index=[2, 412],\n",
      "    is_train=[412],\n",
      "    is_val=[412]\n",
      "  },\n",
      "  \u001b[1m(v1, v1v1, v1)\u001b[0m={\n",
      "    edge_index=[2, 565],\n",
      "    is_train=[565],\n",
      "    is_val=[565]\n",
      "  }\n",
      ")\n",
      "----Batch 1----\n",
      "HeteroData(\n",
      "  \u001b[1mv0\u001b[0m={\n",
      "    x=[76, 231],\n",
      "    y=[76],\n",
      "    train_mask=[76],\n",
      "    val_mask=[76],\n",
      "    test_mask=[76]\n",
      "  },\n",
      "  \u001b[1mv1\u001b[0m={ x=[110, 171] },\n",
      "  \u001b[1m(v0, v0v0, v0)\u001b[0m={\n",
      "    edge_index=[2, 298],\n",
      "    is_train=[298],\n",
      "    is_val=[298]\n",
      "  },\n",
      "  \u001b[1m(v1, v1v1, v1)\u001b[0m={\n",
      "    edge_index=[2, 479],\n",
      "    is_train=[479],\n",
      "    is_val=[479]\n",
      "  }\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "loader3 = conn.gds.graphLoader(\n",
    "    v_in_feats={\"v0\": [\"x\"],\n",
    "                \"v1\": [\"x\"]},\n",
    "    v_out_labels={\"v0\": [\"y\"]},\n",
    "    v_extra_feats={\"v0\": [\"train_mask\", \"val_mask\", \"test_mask\"]},\n",
    "    e_extra_feats={\"v0v0\": [\"is_train\", \"is_val\"],\n",
    "                    \"v1v1\": [\"is_train\", \"is_val\"]},\n",
    "    batch_size=1024,\n",
    "    shuffle=False,\n",
    "    filter_by=None,\n",
    "    output_format=\"PyG\",\n",
    "    add_self_loop=False,\n",
    "    loader_id=None,\n",
    "    buffer_size=4\n",
    ")\n",
    "for i, batch in enumerate(loader3):\n",
    "    print(\"----Batch {}----\".format(i))\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "52a3d944-b782-44cd-81ae-8f1f193cfaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Batch 0----\n",
      "{'v0': {'x': tensor([[-0.6769,  0.0808,  0.3906,  ..., -1.3234,  2.0952, -0.2452],\n",
      "        [-1.0063, -0.7678,  0.1999,  ...,  0.5784, -0.8078,  0.9916],\n",
      "        [-0.7545,  0.6728,  0.1221,  ...,  1.5865,  1.4805, -0.9357],\n",
      "        ...,\n",
      "        [-1.2434, -0.6484,  0.6525,  ...,  2.1990, -0.5989,  1.5437],\n",
      "        [-0.7531,  1.9722,  1.3593,  ..., -0.4019,  0.5499, -0.7318],\n",
      "        [ 0.6978, -0.3825,  0.8817,  ..., -0.7247, -0.2079, -2.5429]],\n",
      "       dtype=torch.float64), 'y': tensor([5, 7, 8, 2, 7, 9, 4, 7, 7, 1, 6, 3, 8, 1, 4, 7, 4, 9, 2, 4, 1, 9, 6, 4,\n",
      "        8, 5, 8, 4, 8, 1, 7, 6, 7, 0, 7, 6, 5, 3, 1, 5, 9, 2, 3, 9, 3, 8, 1, 4,\n",
      "        4, 9, 9, 1, 8, 7, 5, 0, 6, 0, 1, 0, 4, 6, 4, 9, 9, 7, 8, 7, 1, 1, 1, 1,\n",
      "        2, 9, 1, 2]), 'train_mask': tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False]), 'val_mask': tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False]), 'test_mask': tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False])}}\n",
      "----Batch 1----\n",
      "{'v0': {'x': tensor([[-1.3932, -0.8158,  0.5243,  ...,  0.4610,  1.2749,  0.7621],\n",
      "        [ 1.2477, -0.1522, -1.3978,  ..., -1.2855, -1.1503,  1.1449],\n",
      "        [-1.4369,  0.2455,  0.2291,  ...,  1.4322,  0.0047, -0.4625],\n",
      "        ...,\n",
      "        [-1.8158,  1.0543, -0.6630,  ...,  0.3327, -0.5968, -0.6116],\n",
      "        [-1.1679, -1.1890, -0.6898,  ..., -0.4965,  1.0150,  1.4085],\n",
      "        [ 0.7558, -0.4391, -0.4269,  ..., -0.7579,  0.7578, -1.6766]],\n",
      "       dtype=torch.float64), 'y': tensor([4, 8, 5, 8, 4, 8, 1, 1, 8, 7, 0, 1, 0, 4, 6, 4, 9, 9, 7, 2, 1, 1, 4, 1,\n",
      "        9, 6, 1, 5, 9, 2, 3, 9, 9, 1, 2, 5, 7, 8, 2, 7, 7, 7, 5, 0, 6, 4, 7, 4,\n",
      "        9, 8, 7, 1, 1, 2, 1, 4, 4, 9, 9, 9, 4, 7, 1, 6, 3, 8, 1, 6, 7, 0, 7, 6,\n",
      "        5, 3, 3, 8]), 'train_mask': tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False]), 'val_mask': tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False]), 'test_mask': tensor([False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False, False, False, False, False,\n",
      "        False, False, False, False, False, False])}}\n"
     ]
    }
   ],
   "source": [
    "def process_batch(batch):\n",
    "    return {\"v0\":batch[\"v0\"]}\n",
    "loader4 = conn.gds.graphLoader(\n",
    "    v_in_feats={\"v0\": [\"x\"],\n",
    "                \"v1\": [\"x\"]},\n",
    "    v_out_labels={\"v0\": [\"y\"]},\n",
    "    v_extra_feats={\"v0\": [\"train_mask\", \"val_mask\", \"test_mask\"]},\n",
    "    e_extra_feats={\"v0v0\": [\"is_train\", \"is_val\"],\n",
    "                    \"v1v1\": [\"is_train\", \"is_val\"]},\n",
    "    batch_size=1024,\n",
    "    shuffle=False,\n",
    "    filter_by=None,\n",
    "    output_format=\"PyG\",\n",
    "    add_self_loop=False,\n",
    "    loader_id=None,\n",
    "    buffer_size=4,\n",
    "    callback_fn=process_batch\n",
    ")\n",
    "for i, batch in enumerate(loader4):\n",
    "    print(\"----Batch {}----\".format(i))\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef437fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Testcase3: using Loader with callback_fn to loaddata(via Kafka).  \n",
    "## Results: run successfully, data loaded completely\n",
    "\n",
    "**Note**: Kafka streaming function is only available for the Enterprise Edition. You need to activate the Enterprise Edition to use it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9d31863f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('0qsr8kg4r8kd0a6u4dlq4ue5k2vskaia', 1674821736, '2023-01-27 12:15:36')"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.graphname=\"Cora\"\n",
    "# COMMENT OUT THE LINE BELOW if you are NOT using a graph that requires token authentication\n",
    "conn.getToken(conn.createSecret())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c6ce45-0136-47c5-900a-1e78bc7cb792",
   "metadata": {},
   "source": [
    "#### Configure Kafka\n",
    "Set up Kafka here. Once configured, the settings will be shared with all newly created data loaders and no need to set up Kafka for each loader. Please see official [doc](https://docs.tigergraph.com/pytigergraph/current/gds/gds#_configurekafka) for detailed settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "3a0dbe70-29f9-4205-9f53-e8d4e8883eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.gds.configureKafka(kafka_address =\"your_Kafka_address\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0361abb0-7fff-4de6-8a3a-b8af2a0e34a0",
   "metadata": {},
   "source": [
    "#### Get batches of vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "cba77c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:kafka.coordinator.consumer:group_id is None: disabling auto-commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Batch 0----\n",
      "Data(edge_index=[2, 1050], edge_feat=[1050], is_train=[1050], is_val=[1050], x=[1022, 1433], y=[1022], train_mask=[1022], val_mask=[1022], test_mask=[1022])\n",
      "----Batch 1----\n",
      "Data(edge_index=[2, 1051], edge_feat=[1051], is_train=[1051], is_val=[1051], x=[1264, 1433], y=[1264], train_mask=[1264], val_mask=[1264], test_mask=[1264])\n",
      "----Batch 2----\n",
      "Data(edge_index=[2, 1014], edge_feat=[1014], is_train=[1014], is_val=[1014], x=[1209, 1433], y=[1209], train_mask=[1209], val_mask=[1209], test_mask=[1209])\n",
      "----Batch 3----\n",
      "Data(edge_index=[2, 1036], edge_feat=[1036], is_train=[1036], is_val=[1036], x=[1239, 1433], y=[1239], train_mask=[1239], val_mask=[1239], test_mask=[1239])\n",
      "----Batch 4----\n",
      "Data(edge_index=[2, 1065], edge_feat=[1065], is_train=[1065], is_val=[1065], x=[1163, 1433], y=[1163], train_mask=[1163], val_mask=[1163], test_mask=[1163])\n",
      "----Batch 5----\n",
      "Data(edge_index=[2, 1119], edge_feat=[1119], is_train=[1119], is_val=[1119], x=[1057, 1433], y=[1057], train_mask=[1057], val_mask=[1057], test_mask=[1057])\n",
      "----Batch 6----\n",
      "Data(edge_index=[2, 1070], edge_feat=[1070], is_train=[1070], is_val=[1070], x=[1203, 1433], y=[1203], train_mask=[1203], val_mask=[1203], test_mask=[1203])\n",
      "----Batch 7----\n",
      "Data(edge_index=[2, 1100], edge_feat=[1100], is_train=[1100], is_val=[1100], x=[1266, 1433], y=[1266], train_mask=[1266], val_mask=[1266], test_mask=[1266])\n",
      "----Batch 8----\n",
      "Data(edge_index=[2, 1041], edge_feat=[1041], is_train=[1041], is_val=[1041], x=[1231, 1433], y=[1231], train_mask=[1231], val_mask=[1231], test_mask=[1231])\n",
      "----Batch 9----\n",
      "Data(edge_index=[2, 1010], edge_feat=[1010], is_train=[1010], is_val=[1010], x=[1114, 1433], y=[1114], train_mask=[1114], val_mask=[1114], test_mask=[1114])\n"
     ]
    }
   ],
   "source": [
    "def process_batch(batch):\n",
    "    return batch\n",
    "graph_loader5 = conn.gds.graphLoader(\n",
    "    num_batches=10,\n",
    "    v_in_feats = [\"x\"],\n",
    "    v_out_labels = [\"y\"],\n",
    "    v_extra_feats = [\"train_mask\", \"val_mask\", \"test_mask\"],\n",
    "    e_in_feats=[\"time\"],\n",
    "    e_out_labels=[],\n",
    "    e_extra_feats=[\"is_train\", \"is_val\"],\n",
    "    output_format = \"PyG\",\n",
    "    shuffle=True,\n",
    "    filter_by=None,\n",
    "    callback_fn = process_batch\n",
    ")\n",
    "for i, batch in enumerate(graph_loader5):\n",
    "    print(\"----Batch {}----\".format(i))\n",
    "    print(batch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e00835",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-9.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m81"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "toc-autonumbering": false,
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
