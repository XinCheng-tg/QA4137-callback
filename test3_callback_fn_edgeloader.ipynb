{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "31a41fec-c7f0-4752-b57a-efb428327343",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Data Loaders"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "85d51c63-ed05-43d4-9e02-7d13763b5011",
   "metadata": {},
   "source": [
    "This notebook demonstrates the use of **edge loader** in `pyTigerGraph`. The job of a data loader is to pull data from the TigerGraph database. Currently, the following data loaders are provided:\n",
    "* EdgeLoader, which returns batches of edges.\n",
    "* VertexLoader, which returns batches of vertices.\n",
    "* GraphLoader, which returns randomly sampled (probably disconnected) subgraphs in pandas `dataframe`, `PyG` or `DGL` format.\n",
    "* NeighborLoader, which returns subgraphs using neighbor sampling in `dataframe`, `PyG` or `DGL` format.\n",
    "* EdgeNeighborLoader, which returns subgraphs using neighbor sampling from edges in `dataframe`, `PyG` or `DGL` format.\n",
    "\n",
    "Every data loader above can either get all the batches as a HTTP response (default) or stream every batch through Kafka. The former mechanism is good for testing with small graphs and it is fast, but it subjects to a data size limit of 2GB. For large graphs, the HTTP channel will likely fail due to size limit and network connectivity issues. Streaming via Kafka is offered for data robustness and scalability. Also, Kafka excels at multi-consumer use cases, and it is efficient for model search or hyperparameter tuning when there are multiiple consumers of the same data. \n",
    "\n",
    "The data loaders support both homogeneous and heterogenous graphs. By default, they load from all vertex and edge types and treat the graph as a homogeneous graph. But they also allow users to specify what vertex and edge types to load from and what attributes to load from each type. This way users will get heterogeneous graph outputs."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee9243a4-69ae-4a04-ab82-dc6d393e0cb7",
   "metadata": {},
   "source": [
    "### Connection to Database"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9ff08e15-5d93-4f30-8a9d-6b101b1604e4",
   "metadata": {},
   "source": [
    "The `TigerGraphConnection` class represents a connection to the TigerGraph database. Under the hood, it stores the necessary information to communicate with the database. It is able to perform quite a few database tasks. Please see its [documentation](https://docs.tigergraph.com/pytigergraph/current/intro/) for details."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c2c4b1e8-a0e2-4026-9bb1-218cdc7ca4b9",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "A folder with name Cora already exists in ./tmp. Skip downloading.\n",
      "---- Checking database ----\n",
      "A graph with name Cora already exists in the database. Skip ingestion.\n",
      "Graph name is set to Cora for this connection.\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3d8a3b04be384088821fd7c4b514b529",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "CytoscapeWidget(cytoscape_layout={'name': 'circle', 'animate': True, 'padding': 1}, cytoscape_style=[{'selectoâ€¦"
      ]
     },
     "execution_count": 1,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from pyTigerGraph import TigerGraphConnection\n",
    "import json\n",
    "\n",
    "# Read in DB configs\n",
    "with open('../../config.json', \"r\") as config_file:\n",
    "    config = json.load(config_file)\n",
    "    \n",
    "conn = TigerGraphConnection(\n",
    "    host=config[\"host\"],\n",
    "    username=config[\"username\"],\n",
    "    password=config[\"password\"]\n",
    ")\n",
    "\n",
    "from pyTigerGraph.datasets import Datasets\n",
    "\n",
    "dataset = Datasets(\"Cora\")\n",
    "\n",
    "conn.ingestDataset(dataset, getToken=config[\"getToken\"])\n",
    "\n",
    "from pyTigerGraph.visualization import drawSchema\n",
    "\n",
    "drawSchema(conn.getSchema(force=True))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7ad2cc34-545d-4220-8938-e3eda1797fda",
   "metadata": {},
   "source": [
    "### Edge Loader"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b490831c-409e-4234-9c7c-775273ca698b",
   "metadata": {},
   "source": [
    "`EdgeLoader` pulls batches of edges from database. Specifically, it divides edges into `num_batches` and returns each batch separately. The boolean attribute provided to `filter_by` indicates which edges are included. If you need random batches, set `shuffle` to True.\n",
    "\n",
    "**Note**: For the first time you initialize the loader on a graph in TigerGraph,\n",
    "the initialization might take a minute as it installs the corresponding\n",
    "query to the database and optimizes it. However, the query installation only\n",
    "needs to be done once, so it will take no time when you initialize the loader\n",
    "on the same TG graph again.\n",
    "\n",
    "There are two ways to use the data loader. See\n",
    "[here](https://github.com/TigerGraph-DevLabs/mlworkbench-docs/blob/main/tutorials/basics/2_dataloaders.ipynb) for examples.\n",
    "* First, it can be used as an iterable, which means you can loop through it to get every batch of data. If you load all edges at once (`num_batches=1`), there will be only one batch (of all the edges) in the iterator.\n",
    "* Second, you can access the `data` property of the class directly. If there is only one batch of data to load, it will give you the batch directly instead of an iterator, which might make more sense in that case. If there are multiple batches of data to load, it will return the loader again.\n",
    "\n",
    "Args:\n",
    "* attributes (list or dict, optional):\n",
    "        Edge attributes to be included. If it is a list, then the attributes\n",
    "        in the list from all edge types will be selected. An error will be thrown if\n",
    "        certain attribute doesn't exist in all edge types. If it is a dict, keys of the \n",
    "        dict are edge types to be selected, and values are lists of attributes to be \n",
    "        selected for each edge type. Defaults to None.\n",
    "* batch_size (int, optional):  \n",
    "        Number of edges in each batch.  \n",
    "        Defaults to None.  \n",
    "* num_batches (int, optional):  \n",
    "        Number of batches to split the edges.  \n",
    "        Defaults to 1.  \n",
    "* shuffle (bool, optional):  \n",
    "        Whether to shuffle the edges before loading data.  \n",
    "        Defaults to False.  \n",
    "* filter_by (str, optional):\n",
    "        A boolean attribute used to indicate which edges are included. Defaults to None.\n",
    "* output_format (str, optional):\n",
    "        Format of the output data of the loader. Only\n",
    "        \"dataframe\" is supported. Defaults to \"dataframe\".\n",
    "* loader_id (str, optional):\n",
    "        An identifier of the loader which can be any string. It is\n",
    "        also used as the Kafka topic name. If `None`, a random string will be generated\n",
    "        for it. Defaults to None.\n",
    "* buffer_size (int, optional):\n",
    "        Number of data batches to prefetch and store in memory. Defaults to 4.\n",
    "* timeout (int, optional):\n",
    "        Timeout value for GSQL queries, in ms. Defaults to 300000."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2e469fcf-dd49-459f-8731-5a398d7a66a8",
   "metadata": {},
   "source": [
    "# Testcase1: using edgeLoader with callback_fn to get batches of edges.(for homogeneous graph)    \n",
    "## Results: run successfully, data loaded completely"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "be7bada1-6c98-42ec-a5c5-e72a593615f6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Batch 0----\n",
      "(1185, 4)\n",
      "      source     target  time  is_train\n",
      "0  100663306  116391959     0         0\n",
      "1  100663306  117440546     0         0\n",
      "2  100663306  119537750     0         0\n",
      "3  100663306  127926289     0         0\n",
      "4  100663306  131072005     0         0\n",
      "----Batch 1----\n",
      "(1106, 4)\n",
      "      source     target  time  is_train\n",
      "0  100663303  109051953     0         0\n",
      "1  100663305  108003377     0         0\n",
      "2  100663305  113246292     0         0\n",
      "3  100663306  125829166     0         0\n",
      "4  100663306  126877702     0         0\n",
      "----Batch 2----\n",
      "(979, 4)\n",
      "      source     target  time  is_train\n",
      "0  100663299  116392022     0         0\n",
      "1  100663305  133169167     0         0\n",
      "2  100663329  121634823     0         0\n",
      "3  100663337  123732012     0         0\n",
      "4  100663342  133169175     0         0\n",
      "----Batch 3----\n",
      "(1002, 4)\n",
      "      source     target  time  is_train\n",
      "0  100663297  103809038     0         0\n",
      "1  100663306  113246279     0         0\n",
      "2  100663309  123731975     0         0\n",
      "3  100663310  121634874     0         0\n",
      "4  100663313  128974899     0         0\n",
      "----Batch 4----\n",
      "(1073, 4)\n",
      "      source     target  time  is_train\n",
      "0  101711888  105906238     0         0\n",
      "1  101711889  103809082     0         0\n",
      "2  101711889  112197670     0         0\n",
      "3  101711892  121634853     0         0\n",
      "4  101711893  101711934     0         0\n",
      "----Batch 5----\n",
      "(1168, 4)\n",
      "      source     target  time  is_train\n",
      "0  100663299  114294832     0         0\n",
      "1  100663299  128974914     0         0\n",
      "2  100663301  125829150     0         0\n",
      "3  100663301  132120636     0         0\n",
      "4  100663302  102760494     0         0\n",
      "----Batch 6----\n",
      "(1001, 4)\n",
      "      source     target  time  is_train\n",
      "0  104857602  121634884     0         0\n",
      "1  104857606  104857664     0         0\n",
      "2  104857606  114294828     0         0\n",
      "3  104857606  115343431     0         0\n",
      "4  104857607  121634823     0         0\n",
      "----Batch 7----\n",
      "(989, 4)\n",
      "      source     target  time  is_train\n",
      "0  101711873  113246264     0         0\n",
      "1  101711874  106954776     0         0\n",
      "2  101711874  131072034     0         0\n",
      "3  101711876  108003402     0         0\n",
      "4  101711878  106954769     0         0\n",
      "----Batch 8----\n",
      "(998, 4)\n",
      "      source     target  time  is_train\n",
      "0  100663297  120586255     0         0\n",
      "1  100663298  114294857     0         0\n",
      "2  100663309  104857689     0         0\n",
      "3  100663309  112197716     0         0\n",
      "4  100663309  128974895     0         0\n",
      "----Batch 9----\n",
      "(1055, 4)\n",
      "      source     target  time  is_train\n",
      "0  100663298  106954769     0         0\n",
      "1  100663299  132120655     0         0\n",
      "2  100663300  112197639     0         0\n",
      "3  100663300  130023468     0         0\n",
      "4  100663304  101711922     0         0\n"
     ]
    }
   ],
   "source": [
    "def process_batch(batch):\n",
    "    return batch\n",
    "edge_loader2 = conn.gds.edgeLoader(\n",
    "    num_batches=10,\n",
    "    attributes=[\"time\", \"is_train\"],\n",
    "    shuffle=True,\n",
    "    filter_by=None,\n",
    "    callback_fn = process_batch\n",
    ")\n",
    "for i, batch in enumerate(edge_loader2):\n",
    "    print(\"----Batch {}----\".format(i))\n",
    "    print(batch.shape)\n",
    "    print(batch.head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4917e4af-392d-4c90-bc20-5d40324a30c4",
   "metadata": {},
   "source": [
    "# Testcase2: using edgeLoader with callback_fn to get batchs of edges(for heterogeneous graph).  \n",
    "## case details:using edgeLoader without callback_fn first, then using edgeLoader with the same paprams but set a callback_fn to get part of data.\n",
    "## Results: run successfully, data loaded completely"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7e56def3",
   "metadata": {},
   "source": [
    "Since `Cora` is a homogeneous graph, we will connect to a different graph to demostrate the use case of heterogeneous graphs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "05616b55",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('6thp1g6mjra5a5fp8r34d6b0orthfgjj', 1674814923, '2023-01-27 10:22:03')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.graphname=\"hetero\"\n",
    "\n",
    "# COMMENT OUT THE LINE BELOW if you are NOT using a graph that requires token authentication\n",
    "conn.getToken(conn.createSecret())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a76b9591",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Batch 0----\n",
      "Vertex type: v0v0\n",
      "      source     target is_train is_val\n",
      "0  139460609  137363457        0      0\n",
      "Vertex type: v2v0\n",
      "      source     target is_train is_val\n",
      "0  203423744  144703488        0      0\n",
      "----Batch 1----\n",
      "Vertex type: v0v0\n",
      "      source     target is_train is_val\n",
      "0  136314880  139460608        0      0\n",
      "Vertex type: v2v0\n",
      "      source     target is_train is_val\n",
      "0  175112194  147849219        0      0\n",
      "----Batch 2----\n",
      "Vertex type: v0v0\n",
      "      source     target is_train is_val\n",
      "0  134217729  136314883        0      0\n",
      "Vertex type: v2v0\n",
      "      source     target is_train is_val\n",
      "0  201326592  143654912        0      0\n",
      "----Batch 3----\n",
      "Vertex type: v0v0\n",
      "      source     target is_train is_val\n",
      "0  134217728  136314884        0      0\n",
      "Vertex type: v2v0\n",
      "      source     target is_train is_val\n",
      "0  175112192  139460609        0      0\n",
      "----Batch 4----\n",
      "Vertex type: v0v0\n",
      "      source     target is_train is_val\n",
      "0  134217730  150994945        0      0\n",
      "Vertex type: v2v0\n",
      "      source     target is_train is_val\n",
      "0  175112194  165675009        0      0\n",
      "----Batch 5----\n",
      "Vertex type: v0v0\n",
      "      source     target is_train is_val\n",
      "0  134217732  134217733        0      0\n",
      "Vertex type: v2v0\n",
      "      source     target is_train is_val\n",
      "0  175112193  137363459        0      0\n",
      "----Batch 6----\n",
      "Vertex type: v0v0\n",
      "      source     target is_train is_val\n",
      "0  136314881  137363457        0      0\n",
      "Vertex type: v2v0\n",
      "      source     target is_train is_val\n",
      "0  201326592  134217729        0      0\n",
      "----Batch 7----\n",
      "Vertex type: v0v0\n",
      "      source     target is_train is_val\n",
      "0  134217730  142606338        0      0\n",
      "Vertex type: v2v0\n",
      "      source     target is_train is_val\n",
      "0  201326593  148897792        0      0\n",
      "----Batch 8----\n",
      "Vertex type: v2v0\n",
      "      source     target is_train is_val\n",
      "0  202375170  138412033        0      0\n",
      "Vertex type: v0v0\n",
      "      source     target is_train is_val\n",
      "0  135266304  137363456        0      0\n"
     ]
    }
   ],
   "source": [
    "loader3 = conn.gds.edgeLoader(\n",
    "    attributes={\"v0v0\": [\"is_train\", \"is_val\"],\n",
    "                \"v2v0\": [\"is_train\", \"is_val\"]},\n",
    "    batch_size=200,\n",
    "    shuffle=False,\n",
    "    filter_by=None,\n",
    ")\n",
    "for i, batch in enumerate(loader3):\n",
    "    print(\"----Batch {}----\".format(i))\n",
    "    for j in batch:\n",
    "        print(\"Vertex type:\", j)\n",
    "        print(batch[j].head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "52a3d944-b782-44cd-81ae-8f1f193cfaa1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Batch 0----\n",
      "Vertex type: v0v0\n",
      "      source     target is_train is_val\n",
      "0  136314881  136314881        0      0\n",
      "----Batch 1----\n",
      "Vertex type: v0v0\n",
      "      source     target is_train is_val\n",
      "0  136314880  139460608        0      0\n",
      "----Batch 2----\n",
      "Vertex type: v0v0\n",
      "      source     target is_train is_val\n",
      "0  148897794  139460608        0      0\n",
      "----Batch 3----\n",
      "Vertex type: v0v0\n",
      "      source     target is_train is_val\n",
      "0  137363456  136314884        0      0\n",
      "----Batch 4----\n",
      "Vertex type: v0v0\n",
      "      source     target is_train is_val\n",
      "0  157286401  154140672        0      0\n",
      "----Batch 5----\n",
      "Vertex type: v0v0\n",
      "      source     target is_train is_val\n",
      "0  136314882  135266305        0      0\n",
      "----Batch 6----\n",
      "Vertex type: v0v0\n",
      "      source     target is_train is_val\n",
      "0  136314881  137363457        0      0\n",
      "----Batch 7----\n",
      "Vertex type: v0v0\n",
      "      source     target is_train is_val\n",
      "0  134217730  142606338        0      0\n",
      "----Batch 8----\n",
      "Vertex type: v0v0\n",
      "      source     target is_train is_val\n",
      "0  135266304  137363456        0      0\n"
     ]
    }
   ],
   "source": [
    "def process_batch(batch):\n",
    "    return {\"v0v0\":batch[\"v0v0\"]}\n",
    "loader4 = conn.gds.edgeLoader(\n",
    "    attributes={\"v0v0\": [\"is_train\", \"is_val\"],\n",
    "                \"v2v0\": [\"is_train\", \"is_val\"]},\n",
    "    batch_size=200,\n",
    "    shuffle=False,\n",
    "    filter_by=None,\n",
    "    callback_fn=process_batch\n",
    ")\n",
    "for i, batch in enumerate(loader4):\n",
    "    print(\"----Batch {}----\".format(i))\n",
    "    for j in batch:\n",
    "        print(\"Vertex type:\", j)\n",
    "        print(batch[j].head(1))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aef437fe",
   "metadata": {
    "tags": []
   },
   "source": [
    "# Testcase3: using vertexLoader with callback_fn to loaddata(via Kafka).  \n",
    "## Results: run successfully, data loaded completely\n",
    "\n",
    "**Note**: Kafka streaming function is only available for the Enterprise Edition. You need to activate the Enterprise Edition to use it. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9d31863f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('7baq2t9p5rnula7oqvjtj95hrjkf81rd', 1674814924, '2023-01-27 10:22:04')"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "conn.graphname=\"Cora\"\n",
    "# COMMENT OUT THE LINE BELOW if you are NOT using a graph that requires token authentication\n",
    "conn.getToken(conn.createSecret())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "86c6ce45-0136-47c5-900a-1e78bc7cb792",
   "metadata": {},
   "source": [
    "#### Configure Kafka\n",
    "Set up Kafka here. Once configured, the settings will be shared with all newly created data loaders and no need to set up Kafka for each loader. Please see official [doc](https://docs.tigergraph.com/pytigergraph/current/gds/gds#_configurekafka) for detailed settings."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "3a0dbe70-29f9-4205-9f53-e8d4e8883eb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "conn.gds.configureKafka(kafka_address =\"your_Kafka_address\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0361abb0-7fff-4de6-8a3a-b8af2a0e34a0",
   "metadata": {},
   "source": [
    "#### Get batches of vertices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cba77c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:kafka.coordinator.consumer:group_id is None: disabling auto-commit.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----Batch 0----\n",
      "(1018, 4)\n",
      "      source     target  time  is_train\n",
      "0  100663301  125829150     0         0\n",
      "----Batch 1----\n",
      "(1080, 4)\n",
      "      source     target  time  is_train\n",
      "0  105906176  127926335     0         0\n",
      "----Batch 2----\n",
      "(1062, 4)\n",
      "      source     target  time  is_train\n",
      "0  101711874  106954776     0         0\n",
      "----Batch 3----\n",
      "(1028, 4)\n",
      "      source     target  time  is_train\n",
      "0  103809024  122683444     0         0\n",
      "----Batch 4----\n",
      "(1053, 4)\n",
      "      source     target  time  is_train\n",
      "0  100663299  114294832     0         0\n",
      "----Batch 5----\n",
      "(1041, 4)\n",
      "      source     target  time  is_train\n",
      "0  100663296  106954829     0         0\n",
      "----Batch 6----\n",
      "(1098, 4)\n",
      "      source     target  time  is_train\n",
      "0  101711874  119537750     0         0\n",
      "----Batch 7----\n",
      "(1072, 4)\n",
      "      source     target  time  is_train\n",
      "0  100663297  120586255     0         0\n",
      "----Batch 8----\n",
      "(1036, 4)\n",
      "      source     target  time  is_train\n",
      "0  105906178  110100514     0         0\n",
      "----Batch 9----\n",
      "(1068, 4)\n",
      "      source     target  time  is_train\n",
      "0  103809024  108003408     0         0\n"
     ]
    }
   ],
   "source": [
    "def process_batch(batch):\n",
    "    return batch\n",
    "edge_loader5 = conn.gds.edgeLoader(\n",
    "    num_batches=10,\n",
    "    attributes=[\"time\", \"is_train\"],\n",
    "    shuffle=True,\n",
    "    filter_by=None,\n",
    "    callback_fn = process_batch\n",
    ")\n",
    "for i, batch in enumerate(edge_loader5):\n",
    "    print(\"----Batch {}----\".format(i))\n",
    "    print(batch.shape)\n",
    "    print(batch.head(1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "18e00835",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "environment": {
   "name": "pytorch-gpu.1-9.m81",
   "type": "gcloud",
   "uri": "gcr.io/deeplearning-platform-release/pytorch-gpu.1-9:m81"
  },
  "kernelspec": {
   "display_name": "Python 3.8.9 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.9"
  },
  "toc-autonumbering": false,
  "toc-showtags": false,
  "vscode": {
   "interpreter": {
    "hash": "31f2aee4e71d21fbe5cf8b01ff0e069b9275f58929596ceb00d14d90e3e16cd6"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
